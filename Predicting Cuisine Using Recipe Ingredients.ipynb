{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_df = pd.read_json('train.json')\n",
    "test_df = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39774 samples\n",
      "There are 20 categories\n",
      "There are 6714 unique ingredients\n"
     ]
    }
   ],
   "source": [
    "# Creates set of all ingredients\n",
    "def create_ingredient_set(data):\n",
    "    \n",
    "    ingredient_set = set()\n",
    "    \n",
    "    for list_of_ingredients in data['ingredients']:\n",
    "        for ingredient in list_of_ingredients:\n",
    "            ingredient_set.add(ingredient)\n",
    "            \n",
    "    ingredient_set = sorted(ingredient_set)\n",
    "    \n",
    "    return ingredient_set\n",
    "\n",
    "print('There are {} samples'.format(train_df.shape[0]))\n",
    "print('There are {} categories'.format(train_df['cuisine'].value_counts().shape[0]))\n",
    "print('There are {} unique ingredients'.format(len(create_ingredient_set(train_df))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing each dish as a binary ingredient feature vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to call other helper functions, returns finalized dataframe to perform machine learning on\n",
    "def create_ingredient_df(data):\n",
    "    \n",
    "    ingredient_set = create_ingredient_set(data)\n",
    "    dishes_df = create_dishes_df(data, ingredient_set)\n",
    "    final_df = pd.concat([data, dishes_df], join = 'outer', axis = 1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dataframe of ingredient presence in recipe\n",
    "def create_dishes_df(data, ingredient_set):\n",
    "    \n",
    "    contain_ingredient = []\n",
    "    \n",
    "    for list_of_ingredients in data['ingredients']:\n",
    "        current_dish = []\n",
    "        for ingredient in ingredient_set:\n",
    "            if ingredient in list_of_ingredients:\n",
    "                current_dish.append(1)\n",
    "            else:\n",
    "                current_dish.append(0)\n",
    "        contain_ingredient.append(current_dish) \n",
    "        \n",
    "    dishes = pd.DataFrame(contain_ingredient, columns = ingredient_set)\n",
    "    \n",
    "    return dishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls functions and saves into CSV files\n",
    "\n",
    "train_data = create_ingredient_df(train_df)\n",
    "test_data = create_ingredient_df(test_df)\n",
    "\n",
    "# train_data.to_csv('train.csv', index = False)\n",
    "# test_data.to_csv('test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli outperformed Gaussian in terms of cross validation accuracy. This is because of data set does not follow the normal distribution. It performs much better, at almost twice the efficiency, because bernoulli is a more accurate representation of our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Na√Øve Bayes Classifier with Gaussian distribution prior assumption and Bernoulli distribution prior assumption to perform 3 fold cross-validation on the training set:\n",
    "\n",
    "### Using Logistic Regression Model to perform 3 fold cross-validation on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian:  0.3798461306381053\n",
      "Bernoulli:  0.6835369839593705\n",
      "Logistic: 0.7755568964650275\n"
     ]
    }
   ],
   "source": [
    "label_predict, label_actual = [], []\n",
    "kf = KFold(n_splits=3, shuffle=False)\n",
    "count = 0\n",
    "correct_gaussian = 0\n",
    "correct_bernoulli = 0\n",
    "correct_logistic = 0\n",
    "for train_index, test_index in kf.split(train_data):\n",
    "    train_fold = train_data.iloc[train_index,3:].values.tolist()\n",
    "    train_label = train_data.iloc[train_index,0].values.tolist()\n",
    "    test_fold = train_data.iloc[test_index,3:].values.tolist()\n",
    "    test_label = train_data.iloc[test_index,0].values.tolist()\n",
    "    \n",
    "    clf_gaussian = GaussianNB().fit(train_fold,train_label)\n",
    "    clf_bernoulli = BernoulliNB().fit(train_fold,train_label)\n",
    "    clf_logistic = LogisticRegression().fit(train_fold,train_label)    \n",
    "    \n",
    "    for dish in range(len(test_fold)):\n",
    "        count += 1\n",
    "        if clf_gaussian.predict(np.array(test_fold[dish]).reshape(1, -1)) == test_label[dish]:\n",
    "            correct_gaussian += 1\n",
    "        if clf_bernoulli.predict(np.array(test_fold[dish]).reshape(1, -1)) == test_label[dish]:\n",
    "            correct_bernoulli += 1\n",
    "        if clf_logistic.predict(np.array(test_fold[dish]).reshape(1, -1)) == test_label[dish]:\n",
    "            correct_logistic += 1\n",
    "            \n",
    "print(\"Gaussian: \",correct_gaussian/count)\n",
    "print(\"Bernoulli: \",correct_bernoulli/count)\n",
    "print(\"Logistic:\", correct_logistic/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tshan_19f6h3m\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Created test data based on the list of ingredients from the training data\n",
    "test_data = pd.read_json('test.json')\n",
    "\n",
    "ingredient_set = create_ingredient_set(train_data)\n",
    "\n",
    "contain_ingredient = []\n",
    "for list_of_ingredients in test_data['ingredients']:\n",
    "    current_dish = []\n",
    "    for ingredient in ingredient_set:\n",
    "        if ingredient in list_of_ingredients:\n",
    "            current_dish.append(1)\n",
    "        else:\n",
    "            current_dish.append(0)\n",
    "    contain_ingredient.append(current_dish) \n",
    "    \n",
    "test_data = pd.concat([test_data,pd.DataFrame(contain_ingredient,columns=ingredient_set)],join='outer',axis=1)\n",
    "\n",
    "# Fit logistic regression and store in csv for Kaggle competition submission\n",
    "clf_logistic = LogisticRegression().fit(train_data.iloc[:,3:].values.tolist(),train_data.iloc[:,0].values.tolist())    \n",
    "predict_values = pd.DataFrame(columns=['id','cuisine'])\n",
    "\n",
    "for dish in range(len(test_data)): \n",
    "    predict_values.loc[dish] = (test_data.iloc[dish,0],clf_logistic.predict(np.array(test_data.iloc[dish,2:]).reshape(1, -1))[0])\n",
    "    \n",
    "predict_values.to_csv('results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
