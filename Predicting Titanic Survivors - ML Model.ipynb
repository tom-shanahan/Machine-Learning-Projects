{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "test_df = pd.read_csv('aml_test.csv')\n",
    "train_df = pd.read_csv('aml_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test data\n",
    "\n",
    "test_df.drop(['Last Name'], axis = 1, inplace = True)\n",
    "test_df.drop(['Fare'], axis = 1, inplace = True)\n",
    "\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Replace missing Age's with the average Age of each specific Title group\n",
    "means = []\n",
    "\n",
    "means.append(test_df.loc[test_df['Title'] == 'Mr.']['Age'].mean())\n",
    "means.append(test_df.loc[test_df['Title'] == 'Miss.']['Age'].mean())\n",
    "means.append(test_df.loc[test_df['Title'] == 'Mrs.']['Age'].mean())\n",
    "means.append(test_df.loc[test_df['Title'] == 'Master.']['Age'].mean())\n",
    "means.append(test_df.loc[test_df['Title'] == 'Rare']['Age'].mean())\n",
    "\n",
    "test_df.loc[test_df['Title'] == 'Mr.'] = test_df.loc[test_df['Title'] == 'Mr.'].fillna(means[0])\n",
    "test_df.loc[test_df['Title'] == 'Miss.'] = test_df.loc[test_df['Title'] == 'Miss.'].fillna(means[1])\n",
    "test_df.loc[test_df['Title'] == 'Mrs.'] = test_df.loc[test_df['Title'] == 'Mrs.'].fillna(means[2])\n",
    "test_df.loc[test_df['Title'] == 'Master.'] = test_df.loc[test_df['Title'] == 'Master.'].fillna(means[3])\n",
    "test_df.loc[test_df['Title'] == 'Rare'] = test_df.loc[test_df['Title'] == 'Rare'].fillna(means[4])\n",
    "\n",
    "# Create dummy variables for each Title\n",
    "title_dummies = pd.get_dummies(test_df['Title'])\n",
    "test_df = pd.concat([test_df, title_dummies], axis = 1)\n",
    "test_df.drop(['Title'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train data\n",
    "\n",
    "train_df.drop(['Last Name'], axis = 1, inplace = True)\n",
    "train_df.drop(['Fare'], axis = 1, inplace = True)\n",
    "\n",
    "train_df['Sex'] = train_df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Replace missing Age's with the average Age of each specific Title group\n",
    "\n",
    "means = []\n",
    "\n",
    "means.append(train_df.loc[train_df['Title'] == 'Mr.']['Age'].mean())\n",
    "means.append(train_df.loc[train_df['Title'] == 'Miss.']['Age'].mean())\n",
    "means.append(train_df.loc[train_df['Title'] == 'Mrs.']['Age'].mean())\n",
    "means.append(train_df.loc[train_df['Title'] == 'Master.']['Age'].mean())\n",
    "means.append(train_df.loc[train_df['Title'] == 'Rare']['Age'].mean())\n",
    "\n",
    "train_df.loc[train_df['Title'] == 'Mr.'] = train_df.loc[train_df['Title'] == 'Mr.'].fillna(means[0])\n",
    "train_df.loc[train_df['Title'] == 'Miss.'] = train_df.loc[train_df['Title'] == 'Miss.'].fillna(means[1])\n",
    "train_df.loc[train_df['Title'] == 'Mrs.'] = train_df.loc[train_df['Title'] == 'Mrs.'].fillna(means[2])\n",
    "train_df.loc[train_df['Title'] == 'Master.'] = train_df.loc[train_df['Title'] == 'Master.'].fillna(means[3])\n",
    "train_df.loc[train_df['Title'] == 'Rare'] = train_df.loc[train_df['Title'] == 'Rare'].fillna(means[4])\n",
    "\n",
    "# Create dummy variables for each Title\n",
    "title_dummies = pd.get_dummies(train_df['Title'])\n",
    "train_df = pd.concat([train_df, title_dummies], axis = 1)\n",
    "train_df.drop(['Title'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for model\n",
    "\n",
    "train_passenger = train_df['PassengerId']\n",
    "test_passenger = test_df['PassengerId']\n",
    "\n",
    "X_train = train_df.drop(['Survived', 'PassengerId'], axis = 1)\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "X_test = test_df.drop(['PassengerId'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (891, 14)\n",
      "y_train shape: (891,)\n",
      "X_test shape: (418, 14)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: {}\\ny_train shape: {}\\nX_test shape: {}'.format(X_train.shape, y_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 81.93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "acc_log = round(log_reg.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "print('Logistic Regression Accuracy: {}\\n'.format(acc_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 91.58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rand_for = RandomForestClassifier()\n",
    "\n",
    "\n",
    "rand_for.fit(X_train, y_train)\n",
    "y_pred = rand_for.predict(X_test)\n",
    "\n",
    "acc_log = round(rand_for.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "print('Logistic Regression Accuracy: {}\\n'.format(acc_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(data = y_pred, columns = ['Survived'])\n",
    "final_df = pd.concat([test_passenger, y_pred_df], axis = 1)\n",
    "\n",
    "# Save to either Logistic Re\n",
    "# final_df.to_csv('Titanic_Logistic_Regression_Solutions.csv', index = False)\n",
    "final_df.to_csv('Titanic_Random_Forest_Solutions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
